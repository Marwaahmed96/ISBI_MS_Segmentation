{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356aecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random\n",
    "from math import floor\n",
    "from operator import itemgetter\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from skimage.transform import resize\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "from collections import defaultdict\n",
    "from config import *\n",
    "from images import *\n",
    "from data_utils import *\n",
    "from generator import *\n",
    "from u_net_model import *\n",
    "from reconstruct import *\n",
    "from metric import*\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, Dropout, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Conv3DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "# force channels-last ordering\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "print(tf.keras.backend.image_data_format())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d86baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_csv_path = options[\"history_csv_path\"]\n",
    "weights_path= options['weights_path']\n",
    "initial_weights_path=options['initial_weights_path']\n",
    "train_csv_path = options['train_csv_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6655b406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_path</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study</th>\n",
       "      <th>mask1</th>\n",
       "      <th>mask2</th>\n",
       "      <th>flair</th>\n",
       "      <th>t2</th>\n",
       "      <th>pd</th>\n",
       "      <th>mprage</th>\n",
       "      <th>fold</th>\n",
       "      <th>f5_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training01</td>\n",
       "      <td>_01</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training01</td>\n",
       "      <td>_02</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training01</td>\n",
       "      <td>_03</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training01</td>\n",
       "      <td>_04</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training02</td>\n",
       "      <td>_01</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training02</td>\n",
       "      <td>_02</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training02</td>\n",
       "      <td>_03</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training02</td>\n",
       "      <td>_04</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training03</td>\n",
       "      <td>_01</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training03</td>\n",
       "      <td>_02</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training03</td>\n",
       "      <td>_03</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training03</td>\n",
       "      <td>_04</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training03</td>\n",
       "      <td>_05</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training04</td>\n",
       "      <td>_01</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training04</td>\n",
       "      <td>_02</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training04</td>\n",
       "      <td>_03</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training04</td>\n",
       "      <td>_04</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training05</td>\n",
       "      <td>_01</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training05</td>\n",
       "      <td>_02</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training05</td>\n",
       "      <td>_03</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "      <td>training05</td>\n",
       "      <td>_04</td>\n",
       "      <td>mask1.nii</td>\n",
       "      <td>mask2.nii</td>\n",
       "      <td>flair.nii</td>\n",
       "      <td>t2.nii</td>\n",
       "      <td>pd.nii</td>\n",
       "      <td>mprage.nii</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/media/marwa/F2F25460F2542ADD/MedicalAnalysis/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            root_path  patient_id study  \\\n",
       "0   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training01   _01   \n",
       "1   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training01   _02   \n",
       "2   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training01   _03   \n",
       "3   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training01   _04   \n",
       "4   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training02   _01   \n",
       "5   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training02   _02   \n",
       "6   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training02   _03   \n",
       "7   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training02   _04   \n",
       "8   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training03   _01   \n",
       "9   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training03   _02   \n",
       "10  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training03   _03   \n",
       "11  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training03   _04   \n",
       "12  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training03   _05   \n",
       "13  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training04   _01   \n",
       "14  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training04   _02   \n",
       "15  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training04   _03   \n",
       "16  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training04   _04   \n",
       "17  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training05   _01   \n",
       "18  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training05   _02   \n",
       "19  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training05   _03   \n",
       "20  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  training05   _04   \n",
       "\n",
       "        mask1      mask2      flair      t2      pd      mprage  fold  \\\n",
       "0   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   0.0   \n",
       "1   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   2.0   \n",
       "2   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   3.0   \n",
       "3   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   1.0   \n",
       "4   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   0.0   \n",
       "5   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   1.0   \n",
       "6   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   3.0   \n",
       "7   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   2.0   \n",
       "8   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   0.0   \n",
       "9   mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   0.0   \n",
       "10  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   1.0   \n",
       "11  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   3.0   \n",
       "12  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   2.0   \n",
       "13  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   3.0   \n",
       "14  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   2.0   \n",
       "15  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   0.0   \n",
       "16  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   1.0   \n",
       "17  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   1.0   \n",
       "18  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   0.0   \n",
       "19  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   3.0   \n",
       "20  mask1.nii  mask2.nii  flair.nii  t2.nii  pd.nii  mprage.nii   2.0   \n",
       "\n",
       "                                              f5_path  \n",
       "0   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "1   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "2   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "3   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "4   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "5   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "6   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "7   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "8   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "9   /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "10  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "11  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "12  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "13  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "14  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "15  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "16  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "17  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "18  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "19  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  \n",
       "20  /media/marwa/F2F25460F2542ADD/MedicalAnalysis/...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(train_csv_path)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a300b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_data_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/marwa/F2F25460F2542ADD/MedicalAnalysis/Code/ISBI_MS_Segmentation/data_utils.py:277: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  patches = [new_image[idx] for idx in slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34912, 16, 16, 16, 4) (34912, 16, 16, 16, 1)\n",
      "(34912, 16, 16, 16, 4) patches 34912 modalities 4\n",
      "(29962, 16, 16, 16, 4) (29962, 16, 16, 16, 1)\n",
      "(29962, 16, 16, 16, 4) patches 29962 modalities 4\n"
     ]
    }
   ],
   "source": [
    "data,ref,patches=load_data_patches(options, phase='train',fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=options['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e805e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=ISBIDataset(data=data, options=options, patches=patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef94669",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "idx=0\n",
    "for x,y in gen.__getitem__():\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a9edba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (None, 24, 24, 16, 4)\n",
      "Model: \"u__net__model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 24, 24, 16, 1)     4726966   \n",
      "=================================================================\n",
      "Total params: 4,726,966\n",
      "Trainable params: 4,726,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.functional.Functional at 0x7f1dec3e7f50>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model=U_Net_Model(options['input_shape'],\n",
    "                      options['out_channels'],\n",
    "                      depth = options['depth'], \n",
    "                      initial_learning_rate = options['initial_learning_rate'],\n",
    "                      deconvolution = options['deconvolution'])\n",
    "model.build((None,*options['input_shape']))\n",
    "model.summary()\n",
    "model.layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca67606",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create weights path folder if not exist\n",
    "os.makedirs(os.path.dirname(weights_path), exist_ok=True)\n",
    "\n",
    "# if initial weights not exist create model and saveinitial weights\n",
    "if not os.path.isfile(initial_weights_path):\n",
    "    # create model\n",
    "    model=U_Net_Model(options['input_shape'],\n",
    "                          options['out_channels'],\n",
    "                          depth = options['depth'], \n",
    "                          initial_learning_rate = options['initial_learning_rate'],\n",
    "                          deconvolution = options['deconvolution'])\n",
    "    model.save_weights(initial_weights_path)\n",
    "    print('initial weights added')\n",
    "    \n",
    "df = pd.read_csv(train_csv_path)\n",
    "losses={\"BCEDiceLoss\":BCEDiceLoss}\n",
    "\n",
    "\n",
    "if not os.path.isfile(history_csv_path):\n",
    "    history_df=pd.DataFrame(columns=['epoch','dice_loss','dice_metric','val_dice_loss','val_dice_metric','lr'])\n",
    "    history_df.reset_index(inplace=True)\n",
    "    history_df.drop(columns=['index'],inplace=True)\n",
    "    history_df.to_csv(history_csv_path, index=False)\n",
    "\n",
    "history_df=pd.read_csv(history_csv_path)\n",
    "for k in losses.keys():\n",
    "    for fold in range(options['k_fold']):\n",
    "        loss_weights_path = weights_path+k+\"/\"\n",
    "        os.makedirs(loss_weights_path, exist_ok=True)\n",
    "\n",
    "        train_files,train_files_ref,train_patches=load_data_patches(options, phase='train',fold=fold)\n",
    "        valid_files,valid_files_ref,valid_patches=load_data_patches(options, phase='valid',fold=fold)\n",
    "        \n",
    "        train_generator=ISBIDataset(data=train_files, options=options, patches=train_patches)\n",
    "        valid_generator=ISBIDataset(data=valid_files, options=options, patches=valid_patches)\n",
    "        \n",
    "        \n",
    "        print ('-'*100)\n",
    "        print (\"Fold:\", fold)\n",
    "\n",
    "        # create model\n",
    "        model=U_Net_Model(options['input_shape'],\n",
    "                              options['out_channels'],\n",
    "                              depth = options['depth'], \n",
    "                              initial_learning_rate = options['initial_learning_rate'],\n",
    "                              deconvolution = options['deconvolution'])\n",
    "        #model.summary()\n",
    "        if not isinstance(options['metrics'], list):\n",
    "            options['metrics'] = [options['metrics']]\n",
    "        model.compile(optimizer=Adam(lr=options['initial_learning_rate']), \n",
    "                      loss=losses[k], metrics=options['metrics'],run_eagerly=True)\n",
    "        model.build((None ,*options['input_shape']))\n",
    "        model.load_weights(initial_weights_path)\n",
    "\n",
    "        callbacks = model.get_callbacks(options['weights_file_path'], str(fold),\n",
    "                                initial_learning_rate=options['initial_learning_rate'],\n",
    "                                learning_rate_drop=options['learning_rate_drop'],\n",
    "                                learning_rate_patience=options['patience'],\n",
    "                                early_stopping_patience=options['early_stop'])\n",
    "        \n",
    "\n",
    "        epochs = options['n_epochs']\n",
    "        \n",
    "        # Instantiate an optimizer.\n",
    "        optimizer = keras.optimizers.Adam(options['initial_learning_rate'])\n",
    "\n",
    "        # Prepare the metrics.\n",
    "        train_acc_metric = DiceCoefficient()\n",
    "        val_acc_metric = DiceCoefficient()\n",
    "        \n",
    "        \n",
    "        import time\n",
    "        for epoch in range(epochs):\n",
    "            loss_sum=0.0\n",
    "            start_time = time.time()\n",
    "            tp=tf.keras.metrics.TruePositives()\n",
    "            fn=tf.keras.metrics.FalseNegatives()\n",
    "        \n",
    "            # Iterate over the batches of the dataset.\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_generator.__getitem__()):\n",
    "                # Open a GradientTape to record the operations run\n",
    "                # during the forward pass, which enables auto-differentiation.\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "\n",
    "                    # Compute the loss value for this minibatch.\n",
    "                    loss_value = BCEDiceLoss(y_batch_train, logits)\n",
    "                    loss_sum+=loss_value.numpy()\n",
    "                # Use the gradient tape to automatically retrieve\n",
    "                # the gradients of the trainable variables with respect to the loss.\n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "                # Run one step of gradient descent by updating\n",
    "                # the value of the variables to minimize the loss.\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                \n",
    "                # Update training metric.\n",
    "                train_acc_metric.update_state(y_batch_train, logits)\n",
    "                \n",
    "                tp.update_state(y_batch_train, logits)\n",
    "                fn.update_state(y_batch_train, logits)\n",
    "                # Log every 200 batches.\n",
    "                #if step % 200 == 0:\n",
    "                train_acc = train_acc_metric.result().numpy()/(step+1)\n",
    "                tp_value=tp.result().numpy()\n",
    "                fn_value=fn.result().numpy()\n",
    "                tpr=tp_value/(tp_value+fn_value)\n",
    "                               \n",
    "                print_statement='epoch:{} step {}/{} dice loss: {:0.4}, dice metric: {:0.4}, TPR metric: {:0.4}'\n",
    "                print(print_statement.format(epoch+1,step+1, train_generator.__len__(),loss_sum/(step+1), train_acc, tpr),end='\\r')\n",
    "            \n",
    "            # Run a validation loop at the end of each epoch.\n",
    "            val_loss=0.0\n",
    "            for val_step, (x_batch_val, y_batch_val) in enumerate(valid_generator.__getitem__()):\n",
    "                val_logits = model(x_batch_val, training=False)\n",
    "                # Update val metrics\n",
    "                val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "                loss_value = BCEDiceLoss(y_batch_val, val_logits)\n",
    "                val_loss+=loss_value.numpy()\n",
    "            \n",
    "            val_acc = val_acc_metric.result().numpy()\n",
    "            print(\"\\nValidation over epoch {} dice_loss: {:0.4}, dice metric: {:0.4}, TPR metric: {:0.4}\".format(epoch+1,val_loss/(val_step+1), val_acc/(val_step+1), val_acc/(step+1)))\n",
    "            t=time.time() - start_time\n",
    "            print(\"Time taken: {:2.0}:{:2.0}\".format(t/60,t%60))\n",
    "            model.save_weights(loss_weights_path+'fold{}_epoch{}_model_weights.hdf5'.format(fold,epoch))\n",
    "            #model.optimizer.learning_rate\n",
    "            \n",
    "            df = pd.DataFrame([[epoch+1, loss_sum/(step+1),train_acc,val_loss/(val_step+1),val_acc/(val_step+1) ,options['initial_learning_rate']]], columns=['epoch','dice_loss','dice_metric','val_dice_loss','val_dice_metric','lr'])\n",
    "            history_df=history_df.append(df)\n",
    "            history_df.to_csv(history_csv_path, index=False)\n",
    "            \n",
    "            # Reset training metrics at the end of each epoch\n",
    "            train_acc_metric.reset_states()\n",
    "            val_acc_metric.reset_states()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
